DESIGN:
First source of optimization is your algorithm
Second is Data model
Then comes the other
Unit test: you can isolate a single function (if it only does one task) and run it with good data and bad data: in this way you ca test the single function

WHILE TODAY...:
muops = microoperations

Write non-obfuscated code:
conditional branches are killer of optimization! watch out

Some C-specific hints:
example: volatile variable can't be on a register

focus on the restrict:
Here we have no guarantee that a and b don't overlap! If we put restrict before a and b we are telling to the compiler that there will be no memory overlap: in this way the compiler can perform some optimization

Profile-guided optimization:
you can use gcc â€“fprofile-use (for example) to use the information taken in previous runs (branches f.e.) to optimize your code

Usually L1 is divided 32 KB for op, 32 for data; L2 is usually unified

Cache mapping:
memory block number necessary to store the address of the block to which the cache is referring in this moment

Full mapping is very efficient in putting data in the cache, but is very inefficient in accessing data in the cache! This because the cpu have to access all the blocks in the cache, because the information can be anywhere.
Direct mapping is very efficient and fast in accessing (same address); but it's not good in in inserting data in memory: for example 7 and F must go both in 7! So every time i put one I have to throw away the other one and so on; if these are counters in a loop it's a nightmare
n-way associative is better; this is a n=2 example. Normally the caches are 8-way associative

Actually you are filling the whole cache line with the first miss; that's why it's a miss. the element 1 is loaded, so when you access it it's a hit; and so on with the other elements

Strided access: of course we are jumping across memory! No problem is N is small, everything is in our cache line. If N is big, it's a problem. Would it be better to have strided access on the original matrix? YES! Strided writes are more expensive than strided loads.

writeback to memory: this wouldn't happen if you were writing on the same line

graph: very big difference!! (log scale)

Cache-associativity conflicts:
the last 6 bits of the address tell the inline position. And then, with a given number of sets (N = 2^S), we have in the address, before the bits about the inline position, S bits to indicate the set position.

Hot & cold fields:
you will do more often the movement to another node than the do_something, if you have a very long linked list.
since the key is only one value, when i load it I load all the line. If we put the pointer right after the double, we will already have it in cache. PROXIMITY

[big skip]

The cost of branch mis-prediction: [112]
NB: a for is normally forcasted as true, an if is normally forcasted a false; you can change this. How?

Branch prediction: [141]
In the functions version (see code loop.c) the optimization is done by the system, because he recognizes that a lot of branches are fixed decisions.

146
You could here do the verification of the condition outside of the for loop. Probably faster to do as the code on the slide, because the branch predictor can do the optimization for you since he can understand that there are a lot of 1 and then a lot of 0

147
This is a shifting of the bits; like an integer division for 2 (or multiplication if the shifting is done on the other sense)
In this case i'm shifting by 31 positions
Whatever is the data[ii] value, they are all shifted to the right. If the number is negative, all the bits will be 1, so the number is -1 in binary coding.
Then I perform a logical AND with the negation of t; if we AND with all zeros, the number is 0 so i'm not summing up anything (I'm in the case that data[ii] is not greater than pivot, so i don't want to sum)

150
Calculating both branches
151
The vectorization is done in the following way: with little numbers we can do, in one operation, the condition and sum of all the numbers in this way:
(numbers, ..., )>(P,P,P,P,P,P)
And the multiply the result back to the numbers: 2 operations, now we can do the sum on all the final vector. Note that this can't be done with difficult condition operations.

152
This is not really a branch, this is just an evaluation

156
The fact that in the second case we have 27 in both is due to the fact that the data are unpredictable: failed branch prediction. The code is not stable; in the second case (next slide), it is stable